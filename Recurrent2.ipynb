{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "# We need some other data!!\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "# Flatten the images into a vector\n",
    "flatten = lambda x: ToTensor()(x).view(28**2)\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True,  transform=flatten, download=True)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=flatten)\n",
    "\n",
    "# The digit classes to use\n",
    "#classes = [3, 7]\n",
    "classes=[0, 1, 4, 9]\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.train_labels), pin_memory=cuda)\n",
    "test_loader  = DataLoader(dset_test, batch_size=batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.test_labels), pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_table('ECG5000\\ECG5000_TRAIN.tsv')\n",
    "test_data = pd.read_table('ECG5000\\ECG5000_TEST.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([499, 140])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "train_data.iloc[300,1:140]\n",
    "torch.zeros(train_data.shape[0], train_data.shape[1]-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, window_size=100):\n",
    "    #self.oudataframe = pd.DataFrame(np.random.randn(400, 2))\n",
    "    #self.window_size = window_size\n",
    "    self.traindataframe = train_data\n",
    "\n",
    "  def __len__(self):\n",
    "    return train_data.shape[1]-1 # This is always 140 for this dataset\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    #idx = idx * self.window_size #Indexing should be straight forward here\n",
    "    print('window: {}-{}'.format(idx, idx))\n",
    "    #data = torch.zeros(train_data.shape[0], train_data.shape[1]-1)\n",
    "    #target = torch.zeros(train_data.shape[0],1)\n",
    "    #for i in range(0, train_data.shape[0]):\n",
    "      #data[i] = torch.tensor(self.traindataframe.iloc[i,1:141])\n",
    "      #target[i] = torch.tensor(self.traindataframe.iloc[i,0])\n",
    "    data = torch.tensor(self.traindataframe.iloc[idx,1:141])\n",
    "    target = torch.tensor(self.traindataframe.iloc[idx,0])\n",
    "    return data, target\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, window_size=100):\n",
    "    #self.oudataframe = pd.DataFrame(np.random.randn(400, 2))\n",
    "    #self.window_size = window_size\n",
    "    self.testdataframe = train_data\n",
    "\n",
    "  def __len__(self):\n",
    "    return train_data.shape[1]-1 # This is always 140 for this dataset\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    #idx = idx * self.window_size #Indexing should be straight forward here\n",
    "    print('window: {}-{}'.format(idx, idx))\n",
    "    #data = torch.zeros(test_data.shape[0], test_data.shape[1]-1)\n",
    "    #target = torch.zeros(test_data.shape[0],1)\n",
    "    #for i in range(0, train_data.shape[0]):\n",
    "      #data[i] = torch.tensor(self.testdataframe.iloc[i,1:141])\n",
    "      #target[i] = torch.tensor(self.testdataframe.iloc[i,0])\n",
    "    data = torch.tensor(self.testdataframe.iloc[idx,1:141])\n",
    "    target = torch.tensor(self.testdataframe.iloc[idx,0])\n",
    "    return data, target\n",
    "\n",
    "dset_train = TrainDataset()\n",
    "dset_test = TestDataset()\n",
    "batch_size = 5\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size)\n",
    "                          #,sampler=stratified_sampler(dset_train.train_labels), pin_memory=cuda)\n",
    "test_loader  = DataLoader(dset_test, batch_size=batch_size) \n",
    "                          #,sampler=stratified_sampler(dset_test.test_labels), pin_memory=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window: 0-0\n",
      "window: 1-1\n",
      "window: 2-2\n",
      "window: 3-3\n",
      "window: 4-4\n",
      "torch.Size([5, 140])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = next(iter(test_loader))\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(1, 128, bidirectional=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTM(input_dim, hidden_dim,\n",
    "                            n_layers, bidirectional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=140, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=140, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# define size variables\n",
    "num_features = 28**2\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # We encode the data onto the latent space using two linear layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=140, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            # A Gaussian is fully characterised by its mean and variance\n",
    "            nn.Linear(in_features=128, out_features=2*self.latent_features) # <- note the 2*latent_features\n",
    "        )\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_features, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=140)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        #x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "latent_features = 5\n",
    "num_samples = 10\n",
    "\n",
    "net = VariationalAutoencoder(latent_features, num_samples)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): LSTM(1, 128, bidirectional=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): LSTM(10, 128, bidirectional=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# define size variables\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "n_layers = 1\n",
    "z_dim = 10\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "\n",
    "        # We encode the data onto the latent space using two linear layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.LSTM(input_dim, hidden_dim,\n",
    "                            n_layers, bidirectional=True),\n",
    "            nn.Tanh(),\n",
    "            # A Gaussian is fully characterised by its mean and variance\n",
    "            # A Hidden layer that produces 10 outputs from 10 inputs (??)\n",
    "            nn.Linear(hidden_dim, out_features=z_dim) \n",
    "        )\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.LSTM(z_dim, hidden_dim,\n",
    "                            n_layers, bidirectional=True),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        #sigma = torch.exp(log_var/2)\n",
    "        #We use softplus as in the article\n",
    "        sigma = nn.functional.softplus(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "latent_features = 10\n",
    "num_samples = 10\n",
    "\n",
    "net = VariationalAutoencoder(latent_features, num_samples)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "\n",
    "def ELBO_loss(y, t, mu, log_var):\n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "    likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "    likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1)\n",
    "\n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood) - torch.mean(kl)\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl.sum()\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = ELBO_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window: 0-0\n",
      "window: 1-1\n",
      "window: 2-2\n",
      "window: 3-3\n",
      "window: 4-4\n",
      "torch.Size([5, 140])\n",
      "torch.Size([5, 140])\n",
      "torch.Size([5, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "x = Variable(x)\n",
    "\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "\n",
    "outputs = net(x)\n",
    "\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "#loss, kl = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "#print(loss)\n",
    "#print(kl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0170e-02,  6.7447e-02, -9.0022e-02, -6.7385e-02,  4.9073e-02,\n",
      "        -4.5537e-02, -9.4199e-03, -1.0618e-02, -3.6856e-02, -1.0409e-02,\n",
      "         1.5100e-01, -6.4907e-02,  6.8316e-02,  1.7823e-01,  1.6770e-01,\n",
      "        -1.4425e-01,  2.5562e-02, -5.4184e-02, -3.8584e-02,  8.8814e-02,\n",
      "         4.1699e-02, -8.6738e-02,  7.2881e-02,  1.0035e-01, -8.3512e-02,\n",
      "        -4.9836e-02,  6.0432e-02,  5.1704e-02,  7.1146e-02,  7.8680e-02,\n",
      "         7.5735e-02, -2.5655e-02,  9.3454e-03,  3.7206e-02, -1.4947e-02,\n",
      "        -7.2569e-03, -1.3486e-02,  9.5814e-02, -1.3894e-01,  6.2074e-02,\n",
      "        -7.0619e-02, -9.1724e-02, -2.8053e-02, -1.9009e-01, -3.2121e-02,\n",
      "         1.7492e-01,  2.5640e-02,  1.4209e-01, -1.0982e-01, -6.9626e-03,\n",
      "         1.8786e-02,  4.0107e-02,  2.2223e-02, -4.7197e-02, -7.5971e-02,\n",
      "         1.2898e-01,  2.5099e-02, -7.1415e-02,  3.5252e-02,  5.1161e-02,\n",
      "         1.4526e-01,  1.4704e-01, -9.2392e-02, -6.6892e-02, -9.1430e-02,\n",
      "         5.5615e-02, -1.1123e-02, -3.8603e-03, -1.0434e-01,  2.6532e-02,\n",
      "        -1.8250e-01,  5.0046e-02, -1.4606e-01, -3.2143e-03,  1.0897e-01,\n",
      "        -5.1958e-02,  9.4412e-02,  3.9945e-03, -3.2553e-02, -4.5151e-02,\n",
      "        -1.4167e-01,  4.0666e-02, -9.2529e-02,  1.8613e-02,  2.0837e-02,\n",
      "         7.9417e-02,  1.3244e-02, -2.3239e-02,  1.2236e-01,  1.8970e-02,\n",
      "         8.0631e-02,  1.6163e-01, -2.6018e-02,  8.4681e-02,  1.2356e-01,\n",
      "        -5.4378e-02,  2.2857e-02, -1.8754e-02,  4.1835e-02, -3.2762e-02,\n",
      "        -4.7467e-02, -8.9213e-02,  3.5931e-02, -3.6284e-02, -8.2915e-02,\n",
      "         6.0345e-02,  1.0143e-01, -1.5039e-01,  6.1106e-02,  7.4709e-02,\n",
      "         1.0952e-01,  7.4058e-02,  9.6301e-02, -2.1636e-01,  6.2366e-02,\n",
      "         1.9748e-02,  1.3129e-04,  4.1339e-03,  4.5180e-02,  4.6687e-02,\n",
      "        -3.3210e-02,  1.5987e-02, -9.4009e-03,  3.0350e-02, -5.0634e-02,\n",
      "         4.0578e-02, -4.9149e-02, -3.7524e-02,  3.2777e-02, -6.9750e-02,\n",
      "         7.0903e-02, -6.2095e-02,  3.5398e-02,  6.6677e-02, -2.3134e-03,\n",
      "         1.0223e-01, -2.1966e-01,  5.8637e-02, -1.8912e-01,  1.0586e-01],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([-5.6709e-01, -2.5935e+00, -3.8742e+00, -4.5841e+00, -4.1874e+00,\n",
      "        -3.1515e+00, -1.7429e+00, -1.4907e+00, -1.1836e+00, -3.9423e-01,\n",
      "        -2.8290e-01, -3.5693e-01, -2.8730e-01, -3.9949e-01, -4.7324e-01,\n",
      "        -3.7905e-01, -3.9904e-01, -1.7859e-01, -3.3952e-01, -4.9845e-01,\n",
      "        -3.3725e-01, -4.2548e-01, -4.2395e-01, -4.6317e-01, -4.9325e-01,\n",
      "        -5.4975e-01, -5.2983e-01, -5.3093e-01, -5.0236e-01, -4.1737e-01,\n",
      "        -5.2635e-01, -4.7100e-01, -6.7678e-01, -8.9861e-01, -6.1057e-01,\n",
      "        -5.3016e-01, -7.6567e-01, -5.8194e-01, -5.3785e-01, -5.5639e-01,\n",
      "        -4.3802e-01, -4.3625e-01, -4.0011e-01, -1.3499e-01, -2.3935e-01,\n",
      "        -1.2024e-01, -1.9714e-03,  2.8500e-01,  3.1565e-01,  1.0736e-01,\n",
      "         1.0952e-01,  1.5808e-01,  2.9190e-01,  2.6129e-01,  1.8841e-01,\n",
      "         1.4065e-01,  2.6337e-01,  2.8721e-01,  3.1432e-01,  1.7794e-01,\n",
      "         1.3829e-01,  3.2107e-01,  4.5817e-01,  2.5192e-01,  2.6135e-01,\n",
      "         2.7749e-01,  2.9879e-01,  4.5908e-01,  4.1915e-01,  5.2051e-01,\n",
      "         5.3776e-01,  6.0321e-01,  4.7563e-01,  5.2169e-01,  7.3525e-01,\n",
      "         7.2954e-01,  7.1852e-01,  4.9843e-01,  5.4544e-01,  6.0483e-01,\n",
      "         5.2130e-01,  3.9438e-01,  4.0502e-01,  5.9756e-01,  5.3113e-01,\n",
      "         3.7765e-01,  4.6770e-01,  4.5757e-01,  3.4112e-01,  4.0791e-01,\n",
      "         4.5913e-01,  4.0394e-01,  2.9819e-01,  4.6110e-01,  6.6466e-01,\n",
      "         5.8776e-01,  7.0132e-01,  9.1720e-01,  1.2480e+00,  1.5056e+00,\n",
      "         1.6401e+00,  1.8110e+00,  2.1854e+00,  2.2630e+00,  2.0529e+00,\n",
      "         1.8905e+00,  1.7930e+00,  1.5648e+00,  1.2346e+00,  9.0030e-01,\n",
      "         5.5196e-01,  2.5822e-01, -1.2859e-01, -9.2585e-02, -1.6861e-01,\n",
      "        -4.9599e-01, -3.9503e-01, -3.2824e-01, -4.4814e-01, -2.6823e-01,\n",
      "        -4.5641e-01, -3.5787e-01, -3.1751e-01, -4.3411e-01, -5.4920e-01,\n",
      "        -3.2462e-01, -2.6808e-01, -2.2038e-01, -1.1743e-01,  6.1406e-01,\n",
      "         1.2848e+00,  8.8607e-01,  5.3145e-01,  3.1138e-01, -2.1919e-02,\n",
      "        -7.1368e-01, -5.3220e-01,  3.2110e-01,  9.0423e-01, -4.2180e-01])\n"
     ]
    }
   ],
   "source": [
    "print(x_hat[1,:])\n",
    "print(x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataSet = TestDataset()\n",
    "#dataloader = DataLoader(dataSet, batch_size=2, shuffle=False)\n",
    "#for idx, (data, target) in enumerate(dataloader):\n",
    "#    print('BatchIdx {}, data.shape {}, target.shape {}'.format(\n",
    "#            idx, data.shape, target.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
